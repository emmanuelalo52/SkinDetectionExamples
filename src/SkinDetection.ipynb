{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W1rR6pjzR8Y"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pytorch-ignite\n",
        "!git clone https://github.com/karaposu/SkinDetectionExamples.git\n",
        "%cd SkinDetectionExamples/src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj1T3xNVzTGx"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from typing import Dict\n",
        "import itertools\n",
        "import torch\n",
        "import cv2\n",
        "import numpy\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import pathlib\n",
        "import functools\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from bisenetv2 import BiSeNetV2\n",
        "from visualisation import draw_results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image as im\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skimage.exposure\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelweight=\"data/model_segmentation_realtime_skin_30.pth\"\n",
        "state_dict = torch.load(modelweight,map_location=torch.device('cpu'))\n",
        "\n",
        "model = BiSeNetV2(['skin'])\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUzpBECj8hN0"
      },
      "outputs": [],
      "source": [
        "def draw_results(image: torch.Tensor,\n",
        "                 mask: torch.Tensor,\n",
        "                 \n",
        "                 img_mean=(0.485, 0.456, 0.406),\n",
        "                 img_std=(0.229, 0.224, 0.225)):\n",
        "  \n",
        "    assert image.shape[1:] == mask.shape[1:]\n",
        "    assert mask.dtype == torch.bool\n",
        "\n",
        "    image = image.cpu().numpy()\n",
        "    image = numpy.transpose(image, (1, 2, 0))\n",
        "    image = (image * img_std) + img_mean\n",
        "    image = (255 * image).astype(numpy.uint8)\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    mask = mask.cpu().numpy()\n",
        "\n",
        "\n",
        "def load_image(image_path):\n",
        "    #image is loaded to a given path\n",
        "    image = cv2.imread(image_path)\n",
        "    assert image is not None\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image_width,image_height = (image.shape[1] // 32) * 32\n",
        "\n",
        "    image = image[:image_height, :image_width]\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def createSkinMask(model,targetimage):\n",
        "    \n",
        "    targetimage = cv2.cvtColor(targetimage, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image_width,image_height = (targetimage.shape[1] // 32) * 32\n",
        "    \n",
        "    #resize image to model input size\n",
        "    resized_image = targetimage[:image_height, :image_width]\n",
        "\n",
        "    fn_image_transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), ])\n",
        "\n",
        "    transformed_image = fn_image_transform(resized_image)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        transformed_image = transformed_image.unsqueeze(0)\n",
        "        results = model(transformed_image)['out']\n",
        "        results = torch.sigmoid(results)\n",
        "        \n",
        "        results = results > 0.5\n",
        "        mask=results[0]\n",
        "        mask=mask.squeeze(0)\n",
        "        mask = mask.cpu().numpy()\n",
        "        mask=mask*255\n",
        "        mask = mask.astype('uint8')\n",
        "\n",
        "    return mask,resized_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def applyColorToTargetUsingMaskImage(target, mask,color):\n",
        "    #Color is then applied to a target image\n",
        "    org_target= target.copy()\n",
        "    target[(mask==255)] = color\n",
        "    blended_img = cv2.addWeighted(target, 0.65, org_target, 0.35, 0)\n",
        "    return blended_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "shape_of_colorimage1= (100, 100,3)\n",
        "\n",
        "cimg1=np.ones(shape_of_colorimage1, dtype=np.int16)\n",
        "\n",
        "cimg1[:,:,0]= cimg1[:,:,0]*100\n",
        "cimg1[:,:,1]= cimg1[:,:,1]*150\n",
        "cimg1[:,:,2]= cimg1[:,:,2]*150\n",
        "\n",
        "\n",
        "cimg2=np.ones(shape_of_colorimage1, dtype=np.int16)\n",
        "\n",
        "\n",
        "cimg2[:,:,0]= cimg2[:,:,0]*238\n",
        "cimg2[:,:,1]= cimg2[:,:,1]*75\n",
        "cimg2[:,:,2]= cimg2[:,:,2]*43\n",
        "\n",
        "\n",
        "ave_color = cv2.mean(cimg1)\n",
        "ave_color = np.asarray(ave_color, dtype=np.int16)\n",
        "print(\"ave_color:\",ave_color)\n",
        "\n",
        "\n",
        "desired_color = cv2.mean(cimg2)\n",
        "desired_color = np.asarray(desired_color, dtype=np.int16)\n",
        "print(\"desired_color:\",desired_color)\n",
        "\n",
        "\n",
        "diff_color = desired_color - ave_color\n",
        "\n",
        "print(\"diff_color:\",diff_color)\n",
        "\n",
        "diff_color =diff_color[:3]\n",
        "\n",
        "print(\"diff_color new:\",diff_color)\n",
        "\n",
        "patch_pixels = np.full_like(cimg1, diff_color, dtype=np.int16)\n",
        "\n",
        "print(\"shape patch_pixels :\",patch_pixels.shape)\n",
        "\n",
        "# dtype=cv2.CV_16F\n",
        "\n",
        "new_img = cv2.add(cimg1, patch_pixels)\n",
        "\n",
        "\n",
        "f, axarr = plt.subplots(1,3)\n",
        "axarr[0].imshow(cimg1)\n",
        "axarr[1].imshow(cimg2)\n",
        "axarr[2].imshow(new_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFSkgckmVKNx"
      },
      "outputs": [],
      "source": [
        "image_path =\"data/henderson1.png\"\n",
        "original = cv2.imread(image_path)\n",
        "# original=load_image(image_path)\n",
        "\n",
        "\n",
        "mask,resized_image=createSkinMask(model,original)\n",
        "\n",
        "gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
        "ontop = cv2.addWeighted(mask, 0.5, gray, 0.5, 0)\n",
        "\n",
        "f, axarr = plt.subplots(1,3,figsize=(20, 15))\n",
        "axarr[0].imshow(mask, cmap='gray')\n",
        "axarr[1].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
        "axarr[2].imshow(ontop , cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "zb9wU4LPzmjf",
        "outputId": "47b1e660-156c-4653-a65e-b981e751f96a"
      },
      "outputs": [],
      "source": [
        "image_path2 =\"/content/SkinDetectionExamples/src/data/target_head.png\"\n",
        "head = cv2.imread(image_path2)\n",
        "head = cv2.cvtColor(head, cv2.COLOR_BGR2RGB)\n",
        "head = head.astype('int16')\n",
        "\n",
        "print(\"head.shape: \",head.shape)\n",
        "print(head.dtype)\n",
        "\n",
        "### Get skin pixel \n",
        "desired_color=head[75,100,:]\n",
        "print(desired_color)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "BGjX6BRcmFaj",
        "outputId": "58f36f87-93cf-4ab1-cf0d-7d77f6e420be"
      },
      "outputs": [],
      "source": [
        "# resized_mask=resized_mask*255\n",
        "\n",
        "sample1=mask[950,190]\n",
        "sample2=mask[10,190]\n",
        "print(sample1)\n",
        "print(sample2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_path =\"data/henderson1.png\"\n",
        "target=load_image(image_path)\n",
        "\n",
        "target = target.astype('int16')\n",
        "org_target= target.copy()\n",
        "org_target=np.copy(target)\n",
        "\n",
        "print(\"target.shape: \",target.shape)\n",
        "print(target.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#check out elapsed time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFqyt7UgvaP6",
        "outputId": "fdb3f00a-bf9a-4feb-e22e-eb5560dbb848"
      },
      "outputs": [],
      "source": [
        "#we proceed to load our target image into our functions\n",
        "#color target\n",
        "blended_img =applyColorToTargetUsingMaskImage(target, mask,[220 ,194 ,152])\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"the time used to laps skin is {elapsed_time:.4f} seconds\")\n",
        "\n",
        "\n",
        "f, axarr = plt.subplots(1,3, figsize=(15, 10))\n",
        "axarr[0].imshow(org_target)\n",
        "axarr[1].imshow(target)\n",
        "axarr[2].imshow(blended_img)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9Wwp5-bkk2FO"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
